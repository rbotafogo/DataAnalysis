---
title: "Segmentação Celular"
output: html_notebook
---

```{r}
# install.packages("randomForest")
# install.packages("ROCR")
# install.packages("e1071")
```


# Objetivo

Esse é um relatório sobre "Segmentação de Células" feito a partir de dados obtidos do Livro "Applied Predictive Analytics".  O objetivo é aprender sobre análise preditiva e ferramentas do R, tais como R Markdown e R Notebook para a elaboração de relatórios como esse.

O objetivo da análise é verificar automaticamente se uma célula foi corretamente particionada ou não.

# Os Dados

## Preparando os dados para o projeto

Inicialmente vamos carregar as bibliotecas necessárias: "scales", "ggplot2" e "AppliedPredictiveModeling".  Eseg_traina última contém os dados a serem analisados.

```{r}
# suppressPackageseg_trainartupMessages()

library(scales)
library(ggplot2)
library(caret)
library(randomForest)
library(ROCR)

library(AppliedPredictiveModeling)
data(segmentationOriginal)

confusion = function(conf) {
  percentual = (conf[1, 1] + conf[2, 2]) / sum(conf)
  return (percentual)
};
```

Agora será necessário trabalhar os dados, eliminando algumas colunas que não serão necessárias para a execução da análise.

### Nomenclatura

Uma análise complexa de dados pode requerer a geração de muitos modelos e teseg_traines.  Para garantir que não haverá confusão entre os diversos dataframes e modelos, vamos utilizar a seguinte nomenclatura:

1. <dataframe>: o primeiro item do nome é o nome do dataframe;
2. <dataframe>_train: os dados para treinamento;
3. <dataframe>_teseg_train: os dados para teseg_traine;
4. <dataframe>_train_<método>_fit: o modelo utilizado para fazer a previsão
  + <dataframe>_train_glm_fit: modelo "generalized linear model"
  + <dataframe>_train_cart_fit: modelo de árvore
5. <dataframe>_train_glm_pred: resultado (previsão) da aplicação do modelo (fit) 

```{r}
# separar campos que não serão utilizados durante a análise preditiva

seg_train = subset(segmentationOriginal, segmentationOriginal$Case == "Train")
cell = seg_train$Cell
class = seg_train$Class

# remover as três colunas acima do DF
seg_train = seg_train[, -c(1, 2, 3)]

# remover também as colunas de "seg_trainatus"
status = grep("Status", names(seg_train))
seg_train = seg_train[, -status]
```


Os dados utilizados são dados para a segmentação automática de células, cuja a forma e natureza não precisam ser descritos neseg_traine documento.  

Vemos a seguir uma pequena porção dos dados armazenada na variável "segTrain"


```{r}
head(seg_train)
```

e sua estrutura

```{r}
str(seg_train)
```


A variável "class" contém o valor 1 se a célula foi corretamente particionada e 0 se não.  PS ("Poorly Segmented") e WS ("Well Segmented").  Vemos assim que nos dados para treinamento temos 636 célular mal segmentadas e 373 célular bem segmentadas.

```{r}
summary(class)
```

# Primeiro Modelo

Vamos inicialmente criar um primeiro modelo para prever se uma célula foi bem segmentada (WS) ou mal segmentada (PS).

Usaremos para tal um modelo baseado em "Logiseg_trainic Regression", usando o método "glm".

Mas antes de executarmos o modelo é necessário criar um DataFrame com os as variáveis independentes e a variável dependente:

```{r}
seg_train1 = seg_train
seg_train1$Class = class
```

Vamos verificar a estrutura de seg_train1:

```{r}
str(seg_train1)
```


```{r}
seg_train1_glm_fit = glm(Class ~ ., data=seg_train1, family=binomial())
```

Vemos que o modelo1 não é muito bom pela baixa significância das variáveis independentes na previsão da variável dependente: a grande maioria das variáveis não tem '.', '*', '**', '***'

```{r}
summary(seg_train1_glm_fit)
```


# Trabalhando os Dados

```{r}
seg_train2 = seg_train

# definir como pré-processar os dados
pre_processo = preProcess(seg_train2, method=c("BoxCox", "center", "scale", "pca"))

# aplicar o pre_processo aos dados do próximo modelo
seg_train2 = predict(pre_processo, seg_train2)
```

Vamos olhar agora a eseg_trainrutura de seg_train2Trans:

```{r}
str(seg_train2)
```

# Segundo Modelo

Vamos agora construir nosso DF com as variáveis independentes e a variável dependente:

```{r}
seg_train2$Class = class
str(seg_train2)
```

```{r}
seg_train2_glm_fit = glm(Class ~ ., data = seg_train2, family=binomial())
summary(seg_train2_glm_fit)
```

Observamos agora que o modelo é muito mais robuseg_traino que o anterior, com 6 variáveis independentes com forte impacto no modelo, além de duas com certa relevância.  Vamos, a partir de agora remover componentes, um de cada vez, com pouco impacto no modelo para ver se conseguimos melhorá-lo.

Vamos remover PC15 do modelo, visto que é aquele que tem maior Pr.

# Terceiro Modelo

```{r}
seg_train3 = seg_train2[, -15]
seg_train3_glm_fit = glm(Class ~ ., data = seg_train3, family=binomial())
summary(seg_train3_glm_fit)
```

# Quarto Modelo

```{r}
seg_train4 = seg_train3[, -11]
seg_train4_glm_fit = glm(Class ~ ., data = seg_train4, family=binomial())
summary(seg_train4_glm_fit)
```

# Quinto Modelo

```{r}
seg_train5 = seg_train4[, -12]
seg_train5_glm_fit = glm(Class ~ ., data = seg_train5, family=binomial())
summary(seg_train5_glm_fit)
```

# Sexto Modelo

```{r}
seg_train6 = seg_train5[, -13]
seg_train6_glm_fit = glm(Class ~ ., data = seg_train6, family=binomial())
summary(seg_train6_glm_fit)
```

# Sétimo Modelo

```{r}
seg_train7 = seg_train6[, -10]
seg_train7_glm_fit = glm(Class ~ ., data = seg_train7, family=binomial())
summary(seg_train7_glm_fit)
```

# Oitavo Modelo

```{r}
seg_train8 = seg_train7[, -12]
seg_train8_glm_fit = glm(Class ~ ., data = seg_train8, family=binomial())
summary(seg_train8_glm_fit)
```

# Nono Modelo

```{r}
seg_train9 = seg_train8[, -4]
seg_train9_glm_fit = glm(Class ~ ., data = seg_train9, family=binomial())
summary(seg_train9_glm_fit)
```

# Décimo Modelo

```{r}
seg_train10 = seg_train9[, -10]
seg_train10_glm_fit = glm(Class ~ ., data = seg_train10, family=binomial())
summary(seg_train10_glm_fit)
```

# Décimo Primeiro Modelo

```{r}
seg_train11 = seg_train10[, -10]
seg_train11_glm_fit = glm(Class ~ ., data = seg_train11, family=binomial())
summary(seg_train11_glm_fit)
```

# Décimo Segundo Modelo

```{r}
seg_train12 = seg_train11[, -7]
seg_train12_glm_fit = glm(Class ~ ., data = seg_train12, family=binomial())
summary(seg_train12_glm_fit)
```

# Décimo Terceiro Modelo

```{r}
seg_train13 = seg_train12[, -7]
seg_train13_glm_fit = glm(Class ~ ., data = seg_train13, family=binomial())
summary(seg_train13_glm_fit)
```

# Verificando a qualidade do modelo

Conforme vimos anteriormente, temos 636 casos de células mal segmentadas (PS - Poorly Segmented) e 373 casos de células bem segmentadas (WS - Well Segmented) entre os dados.  Isso nos dá um __baseline__ de: 

```{r}
percent(636 / (636 + 373))
```


```{r}
seg_train13_glm_pred = predict(seg_train13_glm_fit, type = "response")
conf = table(seg_train13$Class, seg_train13_glm_pred > 0.5)
```

```{r}
percent(confusion(conf))
```

Vemos assim uma melhora significativa em relação ao __baseline__ do nosso modelo.  Chegamos a um modelo que tem internamente (in sample) um precisão de 79.3%.

# Testando o modelo nos dados de teste 

```{r}
seg_test = subset(segmentationOriginal, segmentationOriginal$Case == "Test")

class_test = seg_test$Class
case_test = seg_test$Case
cell_test = seg_test$Cell

seg_test = seg_test[, -c(1, 2, 3)]

seg_test_status = grep("Status", names(seg_test))

seg_test = seg_test[, -seg_test_status]

# aplicar as mesmas transformações anteriores para os dados de seg_test, ou seja, "BoxCox", 
# "center", "scale", "pca", já definidas em pre_processo
seg_test13 = predict(pre_processo, newdata = seg_test)
str(seg_test13)
```


```{r}
# eliminar de seg_test todas as variáveis independentes que não entraram no modelo
seg_test13 = seg_test13[, c(1, 2, 3, 5, 6, 7, 12, 19)]

# adicionar a seg_test13 as classes
seg_test13$Class = class_test
str(seg_test13)
```

```{r}
# fazer a previsão dos dados de teste utilizando o melhor modelo que obtivemos:
# seg_train13_glm_fit
seg_test13_glm_pred = predict(seg_train13_glm_fit, newdata = seg_test13, type = "response")

# fazer a confusion matrix para a previsão
conf = table(seg_test13$Class, seg_test13_glm_pred > 0.5)
conf
```


```{r}
percent(confusion(conf))
```

# Tentando melhorar as previsões

## Região em que a probabilidade não é alta

Uma regressão logística feita com glm retorna uma probabilidade de um elemento estar em uma determinada classe.  Sendo assim, é bem provável que os erros encontrados estejam entre as previsões feitas dentro de um intervalo ao redor de 50% de chance.  Vamos verificar essa hipótese a seguir.

Para tal, vamos inicialmente levantar todos os eventos que tem uma probabilidade fora da região de 0.30 a 0.70.  Estes elementos são aqueles com maior assertividade.  Verificamos estes valores tanto para os dados originais quanto para os dados previstos e verificamos a taxa de acerto.

```{r}
# obter os elementos com maior probabilidade de erro, ou seja, aqueles cuja a probabilidade está perto de # 50%.  Posteriormente, o ideal é variar este valor de forma a encontrar o melhor "range".
range = 0.20

# definir a variável erro_pot (erro potencial) como os elementos cujo erro está dentro do range em torno
# de 50%
erro_pot = seg_train13_glm_pred > (0.5 - range) & seg_train13_glm_pred < (0.5 + range) 
```

Verificamos a seguir qual o percentual de acerto dos dados com alta probabilidade, ou seja, aqueles que estão fora de "erro_pot":
```{r}
# obter todos os elementos com alta probabilidade de acerto
altaProb_train = subset(seg_train13$Class, erro_pot == FALSE)
altaProb_length = length(altaProb_train)

# obter todos os elementos previstos com alta probabilidade de acerto
altaProb_train_glm_pred = subset(seg_train13_glm_pred, erro_pot == FALSE)
altaProb_train_glm_pred$Class = altaProb_train_glm_pred > 0.5

# fazer a confusion matrix e verificar o percentual de acerto
conf = table(altaProb_train_glm_pred$Class, altaProb_train)
conf
percent(confusion(conf))
```
Vemos aqui que temos 88.1% de acerto em vez de 80.3%, ou seja, os dados em torno de 50% tem realmente maior probabilidade de estarem errados.

Vamos agora verificar o que ocorre com os dados na área de alta probabilidade de erro:
```{r}
baixaProb_train = subset(seg_train13$Class, erro_pot == TRUE)
baixaProb_length = length(baixaProb_train)

baixaProb_train_pred = subset(seg_train13_glm_pred, erro_pot == TRUE)
baixaProb_train_pred$Class = baixaProb_train_pred > 0.5

conf = table(baixaProb_train_pred$Class, baixaProb_train)
conf
percent(confusion(conf))
```
Vemos aqui que a taxa de acerto dentro da área de baixa probabilidade é realmente significativamente inferior à área de alta probabilidade.  Temos 57.4% de chances de acerto dentro da área de baixa probabilidade versus uma taxa de 88.1% na área de alta probabilidade de acerto.

Quantidade de elementos

* Alta probabilidade: `r altaProb_length`
* Baixa probabilidade: `r baixaProb_length`

```{r}
altaProb_length
baixaProb_length
altaProb_length + baixaProb_length
```


## Utilizando o modelo CART (Árvore de Decisão) para prever os casos de baixa probabilidade
Para tentar melhorar o resultado do sistema como um todo, vamos pegar os elementos na área de baixa probabilidade de acerto e utilizar um segundo modelo preditivo.  Utilizaremos um modelo não linear chamado CART.

```{r}
library(rpart)
library(rpart.plot)
```

Para utilizar o modelo CART nos dados de baixa probabilidade, inicialmente pegamos um subconjunto dos dados de seg_train (os dados originais), onde a probabilidade é baixa, ou seja, erro_pot == TRUE.  Vamos chamar este df de segBaixa_train.

```{r}
# Monta um df de treinamento apenas com os dados com baixa probabilidade
segBaixa_train = subset(seg_train, erro_pot == TRUE)

# obten as classes dos dados de baixa probabilidade
classBaixa = subset(class, erro_pot == TRUE)
segBaixa_train$Class = classBaixa

# monta um modelo para os dados com baixa probabilidade
segBaixa_train_cart_fit = rpart(Class ~ ., data = segBaixa_train, method = "class", control=rpart.control(minsplit=30))
summary(segBaixa_train_cart_fit)
prp(segBaixa_train_cart_fit)
```

Vamos agora verificar a qualidade da previsão interna ("in-sample")

```{r}
segBaixa_train_cart_pred = predict(segBaixa_train_cart_fit, type="class")
length(segBaixa_train$Class)

conf = table(segBaixa_train$Class, segBaixa_train_cart_pred)
conf
percent(confusion(conf))
```
Observamos que foi possível subir a porcentagem de acerto significativamente, de 57,4% para 80.6%. Com este ajuste, obtemos um acerto total de

```{r}
tp = 464 + 87
fp = 42 + 41
fn = 44 + 15
tn = 170 + 146
total = 551+83+59+316

percent((tp+tn) / total)
```
Passamos de um taxa de acerto de 80.3% para 85.9%, uma melhora de mais de 5 pontos percentuais.


## Utilizando randomForest para verificar se é possível melhorar a taxa de acerto para os elementos com baixa probabilidade de erro

Nesta seção vamos utilizar um modelo alternativo, randomForest, para verificar se é possível melhorar ainda mais a taxa de acerto para elementos de baixa propabilidade de acerto do modelo linear.

```{r}
# fazer modelo randomForest
segBaixa_train_rf_fit = randomForest(Class ~ ., data = segBaixa_train, ntree = 200, nodesize = 30)

# fazer as previsões
segBaixa_train_rf_pred = predict(segBaixa_train_rf_fit)

# verificar a confusion matrix
conf = table(segBaixa_train$Class, segBaixa_train_rf_pred)
conf
percent(confusion(conf))
```

As previsões feitas com o randomForest são significativamente inferiores do que as feitas com o modelo CART. 

## Tentando utilizar cross-validation para melhorar o resultado de CART

```{r}
library(e1071)
```

```{r}
fitControl = trainControl(method="cv", number=10)
cartGrid = expand.grid(.cp=(1:50)*0.01)
segBaixa_train_cv = train(Class ~ ., data = segBaixa_train, method = "rpart", trControl = fitControl, tuneGrid = cartGrid)

segBaixa_train_cv
```
```{r}
segBaixa_train_cv_cart_fit = rpart(Class ~ ., data = segBaixa_train, method = "class", control=rpart.control(cp = 0.09))

segBaixa_train_cv_cart_pred = predict(segBaixa_train_cv_cart_fit, type = "class")

summary(segBaixa_train_cv_cart_fit)

# verificar a confusion matrix
conf = table(segBaixa_train$Class, segBaixa_train_cv_cart_pred)
conf
percent(confusion(conf))
```
Usando cross validation obtemos um percentual de 72% de acerto.  Este percentual é inferior aos 80.6% da solução obtica apenas com o modelo CART.  [Se meu entendimento está correto, isto significa que a solução obtida inicialmente com o CART está "overfitting".]

A solução de CART com cross validation, no entanto, é superior à solução de randomForest.  Sendo assim devemos utilizar CART com cross validation para os dados de teste.  Vamos a seguir verificar os resultados com os dados de teste

# Utilizando os modelos nos dados de teste

```{r}
# obter os dados de teste apenas da região de baixa probabilidade
# definir a variável erro_test (erro potencial) como os elementos cujo erro está dentro do range em torno
# de 50%
erro_test = seg_test_glm_pred > (0.5 - range) & seg_test_glm_pred < (0.5 + range)
```

```{r}
bp = subset(seg_test13, erro_test == TRUE)
or = subset(seg_test13_glm_pred > 0.5, erro_test == TRUE)

conf = table(bp$Class, or)
conf
percent(confusion(conf))
```

```{r}
baixaProb_test = subset(seg_test, erro_test == TRUE)
baixaProb_test$Class = subset(class_test, erro_test == TRUE)
length(baixaProb_test$Class)

altaProb_test = subset(seg_test, erro_test == FALSE)
altaProb_test$Class = subset(class_test, erro_test == FALSE)
length(altaProb_test$Class)
```
```{r}
baixaProb_test_cart_pred = predict(segBaixa_train_cart_fit, newdata=baixaProb_test, type = "class")
# baixaProb_test_cart_pred

# verificar a confusion matrix
conf = table(baixaProb_test$Class, baixaProb_test_cart_pred)
conf
percent(confusion(conf))
```

```{r}
baixaProb_test_cv_cart_pred = predict(segBaixa_train_cv_cart_fit, newdata=baixaProb_test, type = "class")
# baixaProb_test_cart_pred

# verificar a confusion matrix
conf = table(baixaProb_test$Class, baixaProb_test_cv_cart_pred)
conf
percent(confusion(conf))
```

