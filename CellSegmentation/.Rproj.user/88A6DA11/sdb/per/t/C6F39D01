{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Segmentação Celular\"\noutput: html_notebook\n---\n\n```{r}\n# install.packages(\"randomForest\")\n# install.packages(\"ROCR\")\n# install.packages(\"e1071\")\n```\n\n\n# Objetivo\n\nEsse é um relatório sobre \"Segmentação de Células\" feito a partir de dados obtidos do Livro \"Applied Predictive Analytics\".  O objetivo é aprender sobre análise preditiva e ferramentas do R, tais como R Markdown e R Notebook para a elaboração de relatórios como esse.\n\nO objetivo da análise é verificar automaticamente se uma célula foi corretamente particionada ou não.\n\n# Os Dados\n\n## Preparando os dados para o projeto\n\nInicialmente vamos carregar as bibliotecas necessárias: \"scales\", \"ggplot2\" e \"AppliedPredictiveModeling\".  Eseg_traina última contém os dados a serem analisados.\n\n```{r}\n# suppressPackageseg_trainartupMessages()\n\nlibrary(scales)\nlibrary(ggplot2)\nlibrary(caret)\nlibrary(randomForest)\nlibrary(ROCR)\n\nlibrary(AppliedPredictiveModeling)\ndata(segmentationOriginal)\n\nconfusion = function(conf) {\n  percentual = (conf[1, 1] + conf[2, 2]) / sum(conf)\n  return (percentual)\n};\n```\n\nAgora será necessário trabalhar os dados, eliminando algumas colunas que não serão necessárias para a execução da análise.\n\n### Nomenclatura\n\nUma análise complexa de dados pode requerer a geração de muitos modelos e teseg_traines.  Para garantir que não haverá confusão entre os diversos dataframes e modelos, vamos utilizar a seguinte nomenclatura:\n\n1. <dataframe>: o primeiro item do nome é o nome do dataframe;\n2. <dataframe>_train: os dados para treinamento;\n3. <dataframe>_teseg_train: os dados para teseg_traine;\n4. <dataframe>_train_<método>_fit: o modelo utilizado para fazer a previsão\n  + <dataframe>_train_glm_fit: modelo \"generalized linear model\"\n  + <dataframe>_train_cart_fit: modelo de árvore\n5. <dataframe>_train_glm_pred: resultado (previsão) da aplicação do modelo (fit) \n\n```{r}\n# separar campos que não serão utilizados durante a análise preditiva\n\nseg_train = subset(segmentationOriginal, segmentationOriginal$Case == \"Train\")\ncell = seg_train$Cell\nclass = seg_train$Class\n\n# remover as três colunas acima do DF\nseg_train = seg_train[, -c(1, 2, 3)]\n\n# remover também as colunas de \"seg_trainatus\"\nstatus = grep(\"Status\", names(seg_train))\nseg_train = seg_train[, -status]\n```\n\n\nOs dados utilizados são dados para a segmentação automática de células, cuja a forma e natureza não precisam ser descritos neseg_traine documento.  \n\nVemos a seguir uma pequena porção dos dados armazenada na variável \"segTrain\"\n\n\n```{r}\nhead(seg_train)\n```\n\ne sua estrutura\n\n```{r}\nstr(seg_train)\n```\n\n\nA variável \"class\" contém o valor 1 se a célula foi corretamente particionada e 0 se não.  PS (\"Poorly Segmented\") e WS (\"Well Segmented\").  Vemos assim que nos dados para treinamento temos 636 célular mal segmentadas e 373 célular bem segmentadas.\n\n```{r}\nsummary(class)\n```\n\n# Primeiro Modelo\n\nVamos inicialmente criar um primeiro modelo para prever se uma célula foi bem segmentada (WS) ou mal segmentada (PS).\n\nUsaremos para tal um modelo baseado em \"Logiseg_trainic Regression\", usando o método \"glm\".\n\nMas antes de executarmos o modelo é necessário criar um DataFrame com os as variáveis independentes e a variável dependente:\n\n```{r}\nseg_train1 = seg_train\nseg_train1$Class = class\n```\n\nVamos verificar a estrutura de seg_train1:\n\n```{r}\nstr(seg_train1)\n```\n\n\n```{r}\nseg_train1_glm_fit = glm(Class ~ ., data=seg_train1, family=binomial())\n```\n\nVemos que o modelo1 não é muito bom pela baixa significância das variáveis independentes na previsão da variável dependente: a grande maioria das variáveis não tem '.', '*', '**', '***'\n\n```{r}\nsummary(seg_train1_glm_fit)\n```\n\n\n# Trabalhando os Dados\n\n```{r}\nseg_train2 = seg_train\n\n# definir como pré-processar os dados\npre_processo = preProcess(seg_train2, method=c(\"BoxCox\", \"center\", \"scale\", \"pca\"))\n\n# aplicar o pre_processo aos dados do próximo modelo\nseg_train2 = predict(pre_processo, seg_train2)\n```\n\nVamos olhar agora a eseg_trainrutura de seg_train2Trans:\n\n```{r}\nstr(seg_train2)\n```\n\n# Segundo Modelo\n\nVamos agora construir nosso DF com as variáveis independentes e a variável dependente:\n\n```{r}\nseg_train2$Class = class\nstr(seg_train2)\n```\n\n```{r}\nseg_train2_glm_fit = glm(Class ~ ., data = seg_train2, family=binomial())\nsummary(seg_train2_glm_fit)\n```\n\nObservamos agora que o modelo é muito mais robuseg_traino que o anterior, com 6 variáveis independentes com forte impacto no modelo, além de duas com certa relevância.  Vamos, a partir de agora remover componentes, um de cada vez, com pouco impacto no modelo para ver se conseguimos melhorá-lo.\n\nVamos remover PC15 do modelo, visto que é aquele que tem maior Pr.\n\n# Terceiro Modelo\n\n```{r}\nseg_train3 = seg_train2[, -15]\nseg_train3_glm_fit = glm(Class ~ ., data = seg_train3, family=binomial())\nsummary(seg_train3_glm_fit)\n```\n\n# Quarto Modelo\n\n```{r}\nseg_train4 = seg_train3[, -11]\nseg_train4_glm_fit = glm(Class ~ ., data = seg_train4, family=binomial())\nsummary(seg_train4_glm_fit)\n```\n\n# Quinto Modelo\n\n```{r}\nseg_train5 = seg_train4[, -12]\nseg_train5_glm_fit = glm(Class ~ ., data = seg_train5, family=binomial())\nsummary(seg_train5_glm_fit)\n```\n\n# Sexto Modelo\n\n```{r}\nseg_train6 = seg_train5[, -13]\nseg_train6_glm_fit = glm(Class ~ ., data = seg_train6, family=binomial())\nsummary(seg_train6_glm_fit)\n```\n\n# Sétimo Modelo\n\n```{r}\nseg_train7 = seg_train6[, -10]\nseg_train7_glm_fit = glm(Class ~ ., data = seg_train7, family=binomial())\nsummary(seg_train7_glm_fit)\n```\n\n# Oitavo Modelo\n\n```{r}\nseg_train8 = seg_train7[, -12]\nseg_train8_glm_fit = glm(Class ~ ., data = seg_train8, family=binomial())\nsummary(seg_train8_glm_fit)\n```\n\n# Nono Modelo\n\n```{r}\nseg_train9 = seg_train8[, -4]\nseg_train9_glm_fit = glm(Class ~ ., data = seg_train9, family=binomial())\nsummary(seg_train9_glm_fit)\n```\n\n# Décimo Modelo\n\n```{r}\nseg_train10 = seg_train9[, -10]\nseg_train10_glm_fit = glm(Class ~ ., data = seg_train10, family=binomial())\nsummary(seg_train10_glm_fit)\n```\n\n# Décimo Primeiro Modelo\n\n```{r}\nseg_train11 = seg_train10[, -10]\nseg_train11_glm_fit = glm(Class ~ ., data = seg_train11, family=binomial())\nsummary(seg_train11_glm_fit)\n```\n\n# Décimo Segundo Modelo\n\n```{r}\nseg_train12 = seg_train11[, -7]\nseg_train12_glm_fit = glm(Class ~ ., data = seg_train12, family=binomial())\nsummary(seg_train12_glm_fit)\n```\n\n# Décimo Terceiro Modelo\n\n```{r}\nseg_train13 = seg_train12[, -7]\nseg_train13_glm_fit = glm(Class ~ ., data = seg_train13, family=binomial())\nsummary(seg_train13_glm_fit)\n```\n\n# Verificando a qualidade do modelo\n\nConforme vimos anteriormente, temos 636 casos de células mal segmentadas (PS - Poorly Segmented) e 373 casos de células bem segmentadas (WS - Well Segmented) entre os dados.  Isso nos dá um __baseline__ de: \n\n```{r}\npercent(636 / (636 + 373))\n```\n\n\n```{r}\nseg_train13_glm_pred = predict(seg_train13_glm_fit, type = \"response\")\nconf = table(seg_train13$Class, seg_train13_glm_pred > 0.5)\n```\n\n```{r}\npercent(confusion(conf))\n```\n\nVemos assim uma melhora significativa em relação ao __baseline__ do nosso modelo.  Chegamos a um modelo que tem internamente (in sample) um precisão de 79.3%.\n\n# Testando o modelo nos dados de teste \n\n```{r}\nseg_test = subset(segmentationOriginal, segmentationOriginal$Case == \"Test\")\n\nclass_test = seg_test$Class\ncase_test = seg_test$Case\ncell_test = seg_test$Cell\n\nseg_test = seg_test[, -c(1, 2, 3)]\n\nseg_test_status = grep(\"Status\", names(seg_test))\n\nseg_test = seg_test[, -seg_test_status]\n\n# aplicar as mesmas transformações anteriores para os dados de seg_test, ou seja, \"BoxCox\", \n# \"center\", \"scale\", \"pca\", já definidas em pre_processo\nseg_test13 = predict(pre_processo, newdata = seg_test)\nstr(seg_test13)\n```\n\n\n```{r}\n# eliminar de seg_test todas as variáveis independentes que não entraram no modelo\nseg_test13 = seg_test13[, c(1, 2, 3, 5, 6, 7, 12, 19)]\n\n# adicionar a seg_test13 as classes\nseg_test13$Class = class_test\nstr(seg_test13)\n```\n\n```{r}\n# fazer a previsão dos dados de teste utilizando o melhor modelo que obtivemos:\n# seg_train13_glm_fit\nseg_test13_glm_pred = predict(seg_train13_glm_fit, newdata = seg_test13, type = \"response\")\n\n# fazer a confusion matrix para a previsão\nconf = table(seg_test13$Class, seg_test13_glm_pred > 0.5)\nconf\n```\n\n\n```{r}\npercent(confusion(conf))\n```\n\n# Tentando melhorar as previsões\n\n## Região em que a probabilidade não é alta\n\nUma regressão logística feita com glm retorna uma probabilidade de um elemento estar em uma determinada classe.  Sendo assim, é bem provável que os erros encontrados estejam entre as previsões feitas dentro de um intervalo ao redor de 50% de chance.  Vamos verificar essa hipótese a seguir.\n\nPara tal, vamos inicialmente levantar todos os eventos que tem uma probabilidade fora da região de 0.30 a 0.70.  Estes elementos são aqueles com maior assertividade.  Verificamos estes valores tanto para os dados originais quanto para os dados previstos e verificamos a taxa de acerto.\n\n```{r}\n# obter os elementos com maior probabilidade de erro, ou seja, aqueles cuja a probabilidade está perto de # 50%.  Posteriormente, o ideal é variar este valor de forma a encontrar o melhor \"range\".\nrange = 0.20\n\n# definir a variável erro_pot (erro potencial) como os elementos cujo erro está dentro do range em torno\n# de 50%\nerro_pot = seg_train13_glm_pred > (0.5 - range) & seg_train13_glm_pred < (0.5 + range) \n```\n\nVerificamos a seguir qual o percentual de acerto dos dados com alta probabilidade, ou seja, aqueles que estão fora de \"erro_pot\":\n```{r}\n# obter todos os elementos com alta probabilidade de acerto\naltaProb_train = subset(seg_train13$Class, erro_pot == FALSE)\naltaProb_length = length(altaProb_train)\n\n# obter todos os elementos previstos com alta probabilidade de acerto\naltaProb_train_glm_pred = subset(seg_train13_glm_pred, erro_pot == FALSE)\naltaProb_train_glm_pred$Class = altaProb_train_glm_pred > 0.5\n\n# fazer a confusion matrix e verificar o percentual de acerto\nconf = table(altaProb_train_glm_pred$Class, altaProb_train)\nconf\npercent(confusion(conf))\n```\nVemos aqui que temos 88.1% de acerto em vez de 80.3%, ou seja, os dados em torno de 50% tem realmente maior probabilidade de estarem errados.\n\nVamos agora verificar o que ocorre com os dados na área de alta probabilidade de erro:\n```{r}\nbaixaProb_train = subset(seg_train13$Class, erro_pot == TRUE)\nbaixaProb_length = length(baixaProb_train)\n\nbaixaProb_train_pred = subset(seg_train13_glm_pred, erro_pot == TRUE)\nbaixaProb_train_pred$Class = baixaProb_train_pred > 0.5\n\nconf = table(baixaProb_train_pred$Class, baixaProb_train)\nconf\npercent(confusion(conf))\n```\nVemos aqui que a taxa de acerto dentro da área de baixa probabilidade é realmente significativamente inferior à área de alta probabilidade.  Temos 57.4% de chances de acerto dentro da área de baixa probabilidade versus uma taxa de 88.1% na área de alta probabilidade de acerto.\n\nQuantidade de elementos\n\n* Alta probabilidade: `r altaProb_length`\n* Baixa probabilidade: `r baixaProb_length`\n\n```{r}\naltaProb_length\nbaixaProb_length\naltaProb_length + baixaProb_length\n```\n\n\n## Utilizando o modelo CART (Árvore de Decisão) para prever os casos de baixa probabilidade\nPara tentar melhorar o resultado do sistema como um todo, vamos pegar os elementos na área de baixa probabilidade de acerto e utilizar um segundo modelo preditivo.  Utilizaremos um modelo não linear chamado CART.\n\n```{r}\nlibrary(rpart)\nlibrary(rpart.plot)\n```\n\nPara utilizar o modelo CART nos dados de baixa probabilidade, inicialmente pegamos um subconjunto dos dados de seg_train (os dados originais), onde a probabilidade é baixa, ou seja, erro_pot == TRUE.  Vamos chamar este df de segBaixa_train.\n\n```{r}\n# Monta um df de treinamento apenas com os dados com baixa probabilidade\nsegBaixa_train = subset(seg_train, erro_pot == TRUE)\n\n# obten as classes dos dados de baixa probabilidade\nclassBaixa = subset(class, erro_pot == TRUE)\nsegBaixa_train$Class = classBaixa\n\n# monta um modelo para os dados com baixa probabilidade\nsegBaixa_train_cart_fit = rpart(Class ~ ., data = segBaixa_train, method = \"class\", control=rpart.control(minsplit=30))\nsummary(segBaixa_train_cart_fit)\nprp(segBaixa_train_cart_fit)\n```\n\nVamos agora verificar a qualidade da previsão interna (\"in-sample\")\n\n```{r}\nsegBaixa_train_cart_pred = predict(segBaixa_train_cart_fit, type=\"class\")\nlength(segBaixa_train$Class)\n\nconf = table(segBaixa_train$Class, segBaixa_train_cart_pred)\nconf\npercent(confusion(conf))\n```\nObservamos que foi possível subir a porcentagem de acerto significativamente, de 57,4% para 80.6%. Com este ajuste, obtemos um acerto total de\n\n```{r}\ntp = 464 + 87\nfp = 42 + 41\nfn = 44 + 15\ntn = 170 + 146\ntotal = 551+83+59+316\n\npercent((tp+tn) / total)\n```\nPassamos de um taxa de acerto de 80.3% para 85.9%, uma melhora de mais de 5 pontos percentuais.\n\n\n## Utilizando randomForest para verificar se é possível melhorar a taxa de acerto para os elementos com baixa probabilidade de erro\n\nNesta seção vamos utilizar um modelo alternativo, randomForest, para verificar se é possível melhorar ainda mais a taxa de acerto para elementos de baixa propabilidade de acerto do modelo linear.\n\n```{r}\n# fazer modelo randomForest\nsegBaixa_train_rf_fit = randomForest(Class ~ ., data = segBaixa_train, ntree = 200, nodesize = 30)\n\n# fazer as previsões\nsegBaixa_train_rf_pred = predict(segBaixa_train_rf_fit)\n\n# verificar a confusion matrix\nconf = table(segBaixa_train$Class, segBaixa_train_rf_pred)\nconf\npercent(confusion(conf))\n```\n\nAs previsões feitas com o randomForest são significativamente inferiores do que as feitas com o modelo CART. \n\n## Tentando utilizar cross-validation para melhorar o resultado de CART\n\n```{r}\nlibrary(e1071)\n```\n\n```{r}\nfitControl = trainControl(method=\"cv\", number=10)\ncartGrid = expand.grid(.cp=(1:50)*0.01)\nsegBaixa_train_cv = train(Class ~ ., data = segBaixa_train, method = \"rpart\", trControl = fitControl, tuneGrid = cartGrid)\n\nsegBaixa_train_cv\n```\n```{r}\nsegBaixa_train_cv_cart_fit = rpart(Class ~ ., data = segBaixa_train, method = \"class\", control=rpart.control(cp = 0.09))\n\nsegBaixa_train_cv_cart_pred = predict(segBaixa_train_cv_cart_fit, type = \"class\")\n\nsummary(segBaixa_train_cv_cart_fit)\n\n# verificar a confusion matrix\nconf = table(segBaixa_train$Class, segBaixa_train_cv_cart_pred)\nconf\npercent(confusion(conf))\n```\nUsando cross validation obtemos um percentual de 72% de acerto.  Este percentual é inferior aos 80.6% da solução obtica apenas com o modelo CART.  [Se meu entendimento está correto, isto significa que a solução obtida inicialmente com o CART está \"overfitting\".]\n\nA solução de CART com cross validation, no entanto, é superior à solução de randomForest.  Sendo assim devemos utilizar CART com cross validation para os dados de teste.  Vamos a seguir verificar os resultados com os dados de teste\n\n# Utilizando os modelos nos dados de teste\n\n```{r}\n# obter os dados de teste apenas da região de baixa probabilidade\n# definir a variável erro_test (erro potencial) como os elementos cujo erro está dentro do range em torno\n# de 50%\nerro_test = seg_test_glm_pred > (0.5 - range) & seg_test_glm_pred < (0.5 + range)\n```\n\n```{r}\nbp = subset(seg_test13, erro_test == TRUE)\nor = subset(seg_test13_glm_pred > 0.5, erro_test == TRUE)\n\nconf = table(bp$Class, or)\nconf\npercent(confusion(conf))\n```\n\n```{r}\nbaixaProb_test = subset(seg_test, erro_test == TRUE)\nbaixaProb_test$Class = subset(class_test, erro_test == TRUE)\nlength(baixaProb_test$Class)\n\naltaProb_test = subset(seg_test, erro_test == FALSE)\naltaProb_test$Class = subset(class_test, erro_test == FALSE)\nlength(altaProb_test$Class)\n```\n```{r}\nbaixaProb_test_cart_pred = predict(segBaixa_train_cart_fit, newdata=baixaProb_test, type = \"class\")\n# baixaProb_test_cart_pred\n\n# verificar a confusion matrix\nconf = table(baixaProb_test$Class, baixaProb_test_cart_pred)\nconf\npercent(confusion(conf))\n```\n\n```{r}\nbaixaProb_test_cv_cart_pred = predict(segBaixa_train_cv_cart_fit, newdata=baixaProb_test, type = \"class\")\n# baixaProb_test_cart_pred\n\n# verificar a confusion matrix\nconf = table(baixaProb_test$Class, baixaProb_test_cv_cart_pred)\nconf\npercent(confusion(conf))\n```\n\n",
    "created" : 1508186637691.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2884387211",
    "id" : "C6F39D01",
    "lastKnownWriteTime" : 1508186646,
    "last_content_update" : 1508186645065,
    "path" : "T:/Rodrigo/DataAnalysis/CellSegmentation/Report.Rmd",
    "project_path" : "Report.Rmd",
    "properties" : {
        "chunk_output_type" : "inline",
        "source_window_id" : ""
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}