"0","start <- Sys.time()"
"0","# train the xgboost learner"
"0","c2_train_xbg_fit <- train("
"0","    x = c2_train,"
"0","    y = c2_target,"
"0","    method = 'xgbTree',"
"0","    metric = 'NormalizedGini',"
"0","    trControl = trControl,"
"0","    tuneGrid = tuneGridXGB)"
"1","+ Fold1.Rep1: nrounds=350, max_depth=4, eta=0.05, gamma=0.05, colsample_bytree=0.75, subsample=0.5, min_child_weight=100"
"1"," "
"1","
"
"1","- Fold1.Rep1: nrounds=350, max_depth=4, eta=0.05, gamma=0.05, colsample_bytree=0.75, subsample=0.5, min_child_weight=100"
"1"," "
"1","
"
"1","+ Fold2.Rep1: nrounds=350, max_depth=4, eta=0.05, gamma=0.05, colsample_bytree=0.75, subsample=0.5, min_child_weight=100"
"1"," "
"1","
"
"1","- Fold2.Rep1: nrounds=350, max_depth=4, eta=0.05, gamma=0.05, colsample_bytree=0.75, subsample=0.5, min_child_weight=100"
"1"," "
"1","
"
"1","+ Fold3.Rep1: nrounds=350, max_depth=4, eta=0.05, gamma=0.05, colsample_bytree=0.75, subsample=0.5, min_child_weight=100"
"1"," "
"1","
"
"1","- Fold3.Rep1: nrounds=350, max_depth=4, eta=0.05, gamma=0.05, colsample_bytree=0.75, subsample=0.5, min_child_weight=100"
"1"," "
"1","
"
"1","+ Fold4.Rep1: nrounds=350, max_depth=4, eta=0.05, gamma=0.05, colsample_bytree=0.75, subsample=0.5, min_child_weight=100"
"1"," "
"1","
"
"1","- Fold4.Rep1: nrounds=350, max_depth=4, eta=0.05, gamma=0.05, colsample_bytree=0.75, subsample=0.5, min_child_weight=100"
"1"," "
"1","
"
"1","+ Fold5.Rep1: nrounds=350, max_depth=4, eta=0.05, gamma=0.05, colsample_bytree=0.75, subsample=0.5, min_child_weight=100"
"1"," "
"1","
"
"1","- Fold5.Rep1: nrounds=350, max_depth=4, eta=0.05, gamma=0.05, colsample_bytree=0.75, subsample=0.5, min_child_weight=100"
"1"," "
"1","
"
"1","Aggregating results
"
"1","Fitting"
"1"," "
"1","final model"
"1"," "
"1","on full training set
"
"0","print(Sys.time() - start)"
"1","Time difference of "
"1","1.461375"
"1"," "
"1","mins"
"1","
"
